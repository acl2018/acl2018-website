SubmissionNumber#=%=#374
FinalPaperTitle#=%=#Disconnected Recurrent Neural Networks for Text Categorization
ShortPaperTitle#=%=#
NumberOfPages#=%=#10
CopyrightSigned#=%=#Baoxin Wang
JobTitle#==#Researcher
Organization#==#Joint Laboratory of HIT and iFLYTEK, iFLYTEK Research, Beijing, China
Abstract#==#Recurrent neural network (RNN) has achieved remarkable performance in text
categorization. RNN can model the entire sequence and capture long-term
dependencies, but it does not do well in extracting key patterns. In contrast,
convolutional neural network (CNN) is good at extracting local and
position-invariant features. In this paper, we present a novel model named
disconnected recurrent neural network (DRNN), which incorporates
position-invariance into RNN. By limiting the distance of information flow in
RNN, the hidden state at each time step is restricted to represent words near
the current position. The proposed model makes great improvements over RNN and
CNN models and achieves the best performance on several benchmark datasets for
text categorization.
Author{1}{Firstname}#=%=#Baoxin
Author{1}{Lastname}#=%=#Wang
Author{1}{Email}#=%=#bxwang2@iflytek.com
Author{1}{Affiliation}#=%=#Joint Laboratory of HIT and iFLYTEK, iFLYTEK Research

==========