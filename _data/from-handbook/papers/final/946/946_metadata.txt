SubmissionNumber#=%=#946
FinalPaperTitle#=%=#Bridging CNNs, RNNs, and Weighted Finite-State Machines
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Roy Schwartz
JobTitle#==#
Organization#==#University of Washington
Abstract#==#Recurrent and convolutional neural networks comprise two distinct families of models that have proven to be useful for encoding natural language utterances. In this paper we present SoPa, a new model that aims to bridge these two approaches. SoPa combines neural representation learning with weighted finite-state automata (WFSAs) to learn a soft version of traditional surface patterns. We show that SoPa is an extension of a one-layer CNN, and that such CNNs are equivalent to a restricted version of SoPa, and accordingly, to a restricted form of WFSA. Empirically, on three text classification tasks, SoPa is comparable or better than both a BiLSTM (RNN) baseline and a CNN baseline, and is particularly useful in small data settings.
Author{1}{Firstname}#=%=#Roy
Author{1}{Lastname}#=%=#Schwartz
Author{1}{Email}#=%=#roysch@cs.washington.edu
Author{1}{Affiliation}#=%=#University of Washington and The Allen Institute for Artificial Intelligence
Author{2}{Firstname}#=%=#Sam
Author{2}{Lastname}#=%=#Thomson
Author{2}{Email}#=%=#sthomson@cs.cmu.edu
Author{2}{Affiliation}#=%=#Carnegie Mellon University
Author{3}{Firstname}#=%=#Noah A.
Author{3}{Lastname}#=%=#Smith
Author{3}{Email}#=%=#nasmith@cs.washington.edu
Author{3}{Affiliation}#=%=#University of Washington

==========