SubmissionNumber#=%=#422
FinalPaperTitle#=%=#Evaluating neural network explanation methods using hybrid documents and morphosyntactic agreement
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Nina Poerner
JobTitle#==#
Organization#==#Center for Information and Language Processing, LMU Munich, Germany
Abstract#==#The behavior of deep neural networks (DNNs) is hard to understand. This makes it necessary to explore post hoc explanation methods. We conduct the first comprehensive evaluation of explanation methods for NLP. To this end, we design two novel evaluation paradigms that cover two important classes of NLP problems: small context and large context problems. Both paradigms require no manual annotation and are therefore broadly applicable. We also introduce LIMSSE, an explanation method inspired by LIME that is designed for NLP. We show empirically that LIMSSE, LRP and DeepLIFT are the most effective explanation methods and recommend them for explaining DNNs in NLP.
Author{1}{Firstname}#=%=#Nina
Author{1}{Lastname}#=%=#Poerner
Author{1}{Email}#=%=#poerner@cis.uni-muenchen.de
Author{1}{Affiliation}#=%=#Center for Information and Language Processing, University of Munich
Author{2}{Firstname}#=%=#Hinrich
Author{2}{Lastname}#=%=#Sch√ºtze
Author{2}{Email}#=%=#inquiries@cislmu.org
Author{2}{Affiliation}#=%=#Center for Information and Language Processing, University of Munich
Author{3}{Firstname}#=%=#Benjamin
Author{3}{Lastname}#=%=#Roth
Author{3}{Email}#=%=#beroth@cis.uni-muenchen.de
Author{3}{Affiliation}#=%=#LMU Munich

==========