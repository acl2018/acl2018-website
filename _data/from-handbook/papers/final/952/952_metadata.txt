SubmissionNumber#=%=#952
FinalPaperTitle#=%=#Sequence-to-sequence Models for Cache Transition Systems
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Xiaochang Peng
JobTitle#==#
Organization#==#University of Rochester
Abstract#==#In this paper, we present a sequence-to-sequence based approach for mapping natural language sentences to AMR semantic graphs. We transform the sequence to graph mapping problem to a word sequence to transition action sequence problem using a special transition system called a cache transition system. To address the sparsity issue of neural AMR parsing, we feed feature embeddings from the transition state to provide relevant local information for each decoder state. We present a monotonic hard attention model for the transition framework to handle the strictly left-to-right alignment between each transition state and the current buffer input focus. We evaluate our neural transition model on the AMR parsing task, and our parser outperforms other sequence-to-sequence approaches and achieves competitive results in comparison with the best-performing models.
Author{1}{Firstname}#=%=#Xiaochang
Author{1}{Lastname}#=%=#Peng
Author{1}{Email}#=%=#pxc.pku@gmail.com
Author{1}{Affiliation}#=%=#University of Rochester
Author{2}{Firstname}#=%=#Linfeng
Author{2}{Lastname}#=%=#Song
Author{2}{Email}#=%=#freesunshine0316@gmail.com
Author{2}{Affiliation}#=%=#University of Rochester
Author{3}{Firstname}#=%=#Daniel
Author{3}{Lastname}#=%=#Gildea
Author{3}{Email}#=%=#gildea@cs.rochester.edu
Author{3}{Affiliation}#=%=#University of Rochester
Author{4}{Firstname}#=%=#Giorgio
Author{4}{Lastname}#=%=#Satta
Author{4}{Email}#=%=#satta@dei.unipd.it
Author{4}{Affiliation}#=%=#Department of Information Engineering, University of Padua

==========