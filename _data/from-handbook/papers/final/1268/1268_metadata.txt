SubmissionNumber#=%=#1268
FinalPaperTitle#=%=#Graph-to-Sequence Learning using Gated Graph Neural Networks
ShortPaperTitle#=%=#
NumberOfPages#=%=#11
CopyrightSigned#=%=#Daniel Emilio Beck
JobTitle#==#
Organization#==#University of Melbourne
Abstract#==#Many NLP applications can be framed as a graph-to-sequence learning problem.
Previous work proposing neural architectures on graph-to-sequence obtained
promising results compared to grammar-based approaches but still rely on
linearisation heuristics and/or standard recurrent networks to achieve the best
performance. In this work propose a new model that encodes the full structural
information contained in the graph. Our architecture couples the recently
proposed Gated Graph Neural Networks with an input transformation that allows
nodes and edges to have their own hidden representations, while tackling the
parameter explosion problem present in previous work. Experimental results
shows that our model outperforms strong baselines in generation from AMR graphs
and syntax-based neural machine translation.
Author{1}{Firstname}#=%=#Daniel
Author{1}{Lastname}#=%=#Beck
Author{1}{Email}#=%=#daniel.e.beck@gmail.com
Author{1}{Affiliation}#=%=#University of Melbourne
Author{2}{Firstname}#=%=#Gholamreza
Author{2}{Lastname}#=%=#Haffari
Author{2}{Email}#=%=#reza.haffari@gmail.com
Author{2}{Affiliation}#=%=#Monash University
Author{3}{Firstname}#=%=#Trevor
Author{3}{Lastname}#=%=#Cohn
Author{3}{Email}#=%=#tcohn@unimelb.edu.au
Author{3}{Affiliation}#=%=#University of Melbourne

==========