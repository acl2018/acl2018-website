SubmissionNumber#=%=#1123
FinalPaperTitle#=%=#Using Intermediate Representations to Solve Math Word Problems
ShortPaperTitle#=%=#
NumberOfPages#=%=#10
CopyrightSigned#=%=#DANQING HUANG
JobTitle#==#
Organization#==#Sun Yat-sen Univerisy, Guangzhou, China
Abstract#==#To solve math word problems, previous statistical approaches attempt at learning a direct mapping from a problem description to its corresponding equation system. However, such mappings do not include the information of a few higher-order operations that cannot be explicitly represented in equations but are required to solve the problem. The gap between natural language and equations makes it difficult for a learned model to generalize from limited data. In this work we present an intermediate meaning representation scheme that tries to reduce this gap. We use a sequence-to-sequence model with a novel attention regularization term to generate the intermediate forms, then execute them to obtain the final answers. Since the intermediate forms are latent, we propose an iterative labeling framework for learning by leveraging supervision signals from both equations and answers. Our experiments show using intermediate forms outperforms directly predicting equations.
Author{1}{Firstname}#=%=#Danqing
Author{1}{Lastname}#=%=#Huang
Author{1}{Email}#=%=#huangdq2@mail2.sysu.edu.cn
Author{1}{Affiliation}#=%=#Sun Yat-sen University
Author{2}{Firstname}#=%=#Jin-Ge
Author{2}{Lastname}#=%=#Yao
Author{2}{Email}#=%=#learning.adversarially@gmail.com
Author{2}{Affiliation}#=%=#Microsoft
Author{3}{Firstname}#=%=#Chin-Yew
Author{3}{Lastname}#=%=#Lin
Author{3}{Email}#=%=#cylin@ptlord.com
Author{3}{Affiliation}#=%=#Microsoft Research
Author{4}{Firstname}#=%=#Qingyu
Author{4}{Lastname}#=%=#Zhou
Author{4}{Email}#=%=#qyzhgm@gmail.com
Author{4}{Affiliation}#=%=#Harbin Institute of Technology
Author{5}{Firstname}#=%=#Jian
Author{5}{Lastname}#=%=#Yin
Author{5}{Email}#=%=#issjyin@mail.sysu.edu.cn
Author{5}{Affiliation}#=%=#Sun Yat-sen University

==========